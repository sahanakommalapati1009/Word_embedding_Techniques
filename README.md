# Word Embedding Techniques using Keras

## Description
This project explores different **word embedding techniques** used in Natural Language Processing (NLP). Word embeddings are crucial for representing words in a continuous vector space, capturing semantic relationships between words.

## Overview
This Jupyter Notebook covers:
- **One-Hot Representation**: A basic way to encode words.
- **Word Embedding Representation**: Using Keras Embedding Layer to create meaningful word vectors.

## Requirements
To run this notebook, install the necessary dependencies:
```bash
pip install tensorflow numpy
```

## Usage
1. Open the notebook in Jupyter:
   ```bash
   jupyter notebook Word_embedding_Techniques.ipynb
   ```
2. Run the cells step by step to understand different word embedding techniques.
3. Modify input data to experiment with different embedding settings.

## Implementation Details
- **Keras** is used for implementing the embedding layer.
- **NumPy** is used for handling numerical computations.


